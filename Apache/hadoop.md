# Apache Hadoop

**Keywords**: `Big Data`, `HDFS`, `MapReduce`, `YARN`, `Distributed Computing`, `Batch`, `Open Source`, `Data Lake`, `Cluster`

---

## üß† Description G√©n√©rale

**Apache Hadoop** est un framework open source pour le stockage et le traitement distribu√© de tr√®s grands volumes de donn√©es. Il repose sur un syst√®me de fichiers distribu√© (HDFS) et un moteur de calcul batch (MapReduce), orchestr√©s par YARN.

Caract√©ristiques principales :
- Stockage distribu√© et tol√©rant aux pannes via HDFS.
- Traitement batch massif avec MapReduce.
- Orchestration des ressources et des jobs via YARN.
- √âcosyst√®me riche : Hive, Pig, HBase, Spark, Oozie, etc.
- D√©ploiement sur clusters on-premise ou cloud (ex : Dataproc, EMR).

---

## üß∞ Composants Principaux

### 1. **HDFS (Hadoop Distributed File System)**
- Syst√®me de fichiers distribu√©, stockage redondant et scalable.

### 2. **MapReduce**
- Mod√®le de programmation pour le traitement batch distribu√©.

### 3. **YARN (Yet Another Resource Negotiator)**
- Gestion des ressources et orchestration des jobs sur le cluster.

### 4. **√âcosyst√®me Hadoop**
- Outils compl√©mentaires : Hive (SQL), Pig (scripts), HBase (NoSQL), Oozie (workflow), Spark (traitement en m√©moire), etc.

---

## üßë‚Äçüíº Cas d‚ÄôUsage

| Cas d‚Äôusage                         | Description |
|------------------------------------|-------------|
| ETL Big Data                        | Traitement batch de gros volumes de donn√©es |
| Data Lake                           | Stockage et pr√©paration de donn√©es non structur√©es |
| Machine Learning distribu√©          | Pr√©paration de donn√©es pour Spark/MLlib |
| Archivage massif                    | Stockage longue dur√©e de donn√©es brutes |
| Migration cloud                     | D√©ploiement sur Dataproc, EMR, HDInsight |

---

## üßë‚Äçüî¨ Exemple d‚ÄôArchitecture : Hadoop sur cluster

1. **Stockage** : Donn√©es sur HDFS, ingestion depuis bases, fichiers, IoT, etc.
2. **Traitement** : Jobs MapReduce ou Spark soumis au cluster.
3. **Orchestration** : YARN g√®re la r√©partition des ressources et l‚Äôex√©cution des jobs.
4. **Sortie** : R√©sultats stock√©s sur HDFS, export√©s vers bases ou data marts.
5. **Surveillance** : Monitoring via outils natifs ou int√©gration avec Prometheus, Grafana.

---

# üöÄ Commandes / Code utiles

### Exemple : Lancer un job MapReduce

```bash
hadoop jar /path/to/hadoop-examples.jar wordcount /input /output
```

## ‚úÖ Bonnes Pratiques

- R√©pliquer les donn√©es (par d√©faut x3) pour la tol√©rance aux pannes.
- Surveiller l‚Äôespace disque et la sant√© du cluster.
- Utiliser YARN pour optimiser l‚Äôallocation des ressources.
- Automatiser les workflows avec Oozie ou Airflow.
- S√©curiser l‚Äôacc√®s avec Kerberos et les ACLs HDFS.
- Privil√©gier Spark pour les traitements interactifs ou en m√©moire.