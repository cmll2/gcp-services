# Apache Hive

**Keywords**: `Big Data`, `SQL`, `Data Warehouse`, `Hadoop`, `ETL`, `Batch`, `Schema-on-Read`, `Open Source`, `Analytics`

---

## ğŸ§  Description GÃ©nÃ©rale

**Apache Hive** est un systÃ¨me dâ€™entrepÃ´t de donnÃ©es open source conÃ§u pour interroger et analyser de grands volumes de donnÃ©es stockÃ©s dans Hadoop. Il permet dâ€™utiliser un langage proche du SQL (HiveQL) pour effectuer des requÃªtes, des analyses et des transformations sur des donnÃ©es distribuÃ©es.

CaractÃ©ristiques principales :
- RequÃªtes SQL (HiveQL) sur des donnÃ©es stockÃ©es dans HDFS, S3, etc.
- ExÃ©cution des requÃªtes via MapReduce, Tez ou Spark.
- Gestion de schÃ©mas (schema-on-read) et de tables partitionnÃ©es.
- Support des UDF/UDAF pour des traitements personnalisÃ©s.
- IntÃ©gration avec lâ€™Ã©cosystÃ¨me Hadoop (HDFS, YARN, Oozie, etc.).

---

## ğŸ§° Composants Principaux

### 1. **Metastore**
- Base de donnÃ©es centralisant les mÃ©tadonnÃ©es des tables, partitions, schÃ©mas.

### 2. **HiveQL**
- Langage de requÃªte similaire Ã  SQL, adaptÃ© au Big Data.

### 3. **Drivers dâ€™exÃ©cution**
- MapReduce, Tez, Spark : moteurs pour exÃ©cuter les requÃªtes HiveQL.

### 4. **Tables et partitions**
- Tables internes ou externes, partitionnement pour optimiser les requÃªtes.

### 5. **UDF/UDAF**
- Fonctions personnalisÃ©es pour enrichir les traitements.

---

## ğŸ§‘â€ğŸ’¼ Cas dâ€™Usage

| Cas dâ€™usage                         | Description |
|------------------------------------|-------------|
| Data Warehouse Big Data             | EntrepÃ´t analytique sur HDFS ou S3 |
| ETL batch                           | Transformation et prÃ©paration de donnÃ©es massives |
| Reporting analytique                | GÃ©nÃ©ration de rapports sur de gros volumes de donnÃ©es |
| Migration SQL vers Hadoop           | Utilisation de SQL sur des donnÃ©es distribuÃ©es |
| Exploration de Data Lake            | Analyse ad hoc sur des donnÃ©es brutes |

---

## ğŸ§‘â€ğŸ”¬ Exemple dâ€™Architecture : Hive sur Hadoop

1. **Stockage** : DonnÃ©es sur HDFS ou S3.
2. **Metastore** : MÃ©tadonnÃ©es centralisÃ©es (MySQL, PostgreSQL, etc.).
3. **Traitement** : RequÃªtes HiveQL exÃ©cutÃ©es via MapReduce, Tez ou Spark.
4. **Orchestration** : Workflows automatisÃ©s avec Oozie ou Airflow.
5. **Sortie** : RÃ©sultats stockÃ©s sur HDFS, S3 ou exportÃ©s vers dâ€™autres systÃ¨mes.

---

# ğŸš€ Commandes / Code utiles

### Exemple : Lancer le shell Hive

```bash
hive
```

### Exemple : CrÃ©er une table Hive

```sql
CREATE TABLE ventes (
  id INT,
  produit STRING,
  montant DOUBLE
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE;
```

## âœ… Bonnes Pratiques

- Utiliser le partitionnement pour accÃ©lÃ©rer les requÃªtes sur de gros volumes.
- Centraliser les mÃ©tadonnÃ©es dans un Metastore robuste.
- PrivilÃ©gier Tez ou Spark pour des performances accrues.
- Documenter les schÃ©mas et les UDF/UDAF personnalisÃ©es.
- SÃ©curiser lâ€™accÃ¨s au Metastore et aux donnÃ©es (Kerberos, ACLs).
- Nettoyer rÃ©guliÃ¨rement les tables temporaires et les partitions obsolÃ¨tes.