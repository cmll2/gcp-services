# Vertex AI

**Keywords**: `ML`, `AutoML`, `Custom Training`, `MLOps`, `Pipelines`, `Model Registry`, `Explainable AI`, `Serverless`, `GCP`, `Managed Services`

---

## üß† Description G√©n√©rale

**Vertex AI** est la plateforme de Machine Learning unifi√©e de Google Cloud. Elle permet de g√©rer **l‚Äôensemble du cycle de vie ML**, de l‚Äôingestion de donn√©es jusqu‚Äô√† l‚Äôinf√©rence, le monitoring, et le r√©entra√Ænement.

Elle int√®gre de mani√®re coh√©rente :
- AutoML
- Entra√Ænement personnalis√©
- D√©ploiement de mod√®les
- Pipelines (ML workflows)
- Feature Store
- Registry (catalogue de mod√®les)
- Monitoring des mod√®les
- Explainable AI (XAI)

---

## üß∞ Composants Principaux

### 1. **AutoML**
- Entra√Ænement automatique de mod√®les (vision, NLP, tabulaire).
- Aucune expertise ML requise.
- Optimisation automatique de l‚Äôarchitecture + hyperparam√®tres.

### 2. **Custom Training**
- Utilisation de frameworks comme TensorFlow, PyTorch, XGBoost, scikit-learn.
- Supporte :
  - Entra√Ænement distribu√©
  - GPU/TPU
  - Jobs Dockeris√©s (`custom containers`)
- Stockage des artefacts dans Cloud Storage.

### 3. **Vertex AI Workbench**
- Environnement Jupyter g√©r√© pour le prototypage.
- Int√©gr√© avec BigQuery, Dataflow, Spark, GCS.
- Possibilit√© de d√©marrer des notebooks "user-managed" ou "serverless".

### 4. **Pipelines**
- Bas√©s sur Kubeflow Pipelines.
- Orchestration d'√©tapes ML (pr√©traitement, entra√Ænement, validation, d√©ploiement).
- Reproductibles, versionn√©s, auditables.

### 5. **Feature Store**
- Stocke, partage et versionne les features.
- Utilisable √† l‚Äôentra√Ænement et √† l‚Äôinf√©rence pour coh√©rence.

### 6. **Model Registry**
- Catalogue de mod√®les versionn√©s.
- Int√®gre validation, audit, promotion vers staging/prod.

### 7. **Model Monitoring**
- Surveille le drift de donn√©es, la performance mod√®le.
- Alertes automatiques.

### 8. **Explainable AI**
- G√©n√®re des explications locales/globales.
- M√©thodes : SHAP, Integrated Gradients, etc.

---

## üßë‚Äçüíº Cas d‚ÄôUsage

| Cas d‚Äôusage                         | Description |
|------------------------------------|-------------|
| Classification d'images            | AutoML Vision ou mod√®le TensorFlow personnalis√© |
| D√©tection de fraude                | Pipelines + mod√®les XGBoost sur donn√©es tabulaires |
| Pr√©diction de churn                | AutoML Tables + Feature Store |
| Analyse de sentiments              | AutoML Text ou fine-tuning BERT |
| Recommandation de contenu          | Entra√Ænement PyTorch + Feature Store |
| D√©tection d‚Äôanomalies industrielles| Custom training + GPU/TPU + d√©ploiement scalable |

---

## üßë‚Äçüî¨ Exemple d‚ÄôArchitecture : Pipeline Vertex AI


[BigQuery](../BigQuery/bigquery.md) (source data)

[Dataflow](../Dataflow/dataflow.md) (ETL)

Vertex AI Training Job (AutoML ou Custom)

[Model-Registry](modelregistry.md) (Model Versioning)

Model Deployment (Endpoint)

Model Monitoring & Retraining Loop


# üöÄ Commandes / Code utiles
Lancer un job de training custom (Python)


```python
from google.cloud import aiplatform

aiplatform.init(project='your-project', location='us-central1')

job = aiplatform.CustomTrainingJob(
    display_name='my-model-training',
    script_path='train.py',
    container_uri='gcr.io/cloud-aiplatform/training/tf-cpu.2-11:latest',
    requirements=['pandas', 'scikit-learn'],
)

model = job.run(
    replica_count=1,
    model_display_name='my-trained-model',
)
Cr√©er un endpoint & d√©ployer un mod√®le
python
Copier
Modifier
endpoint = model.deploy(machine_type='n1-standard-4')
```

## ‚úÖ Bonnes Pratiques

Toujours versionner les datasets avec des identifiants horodat√©s

Utiliser Feature Store pour la coh√©rence entra√Ænement/inf√©rence

Pr√©voir des pipelines reproductibles (Vertex Pipelines)

Int√©grer Model Monitoring d√®s le d√©part

Utiliser custom containers pour le contr√¥le maximal

Activer Explainable AI pour les cas sensibles (finance, sant√©)